# Configura a URL base do servidor Ollama
quarkus.langchainai.ollama.base-url=http://localhost:11434/

# Define o ID do modelo que o LangChainAI irá invocar no Ollama
quarkus.langchainai.ollama.chat.model-id=gpt-oss:20b

# Define um timeout para a chamada (60 segundos)
quarkus.langchainai.ollama.timeout=60s
